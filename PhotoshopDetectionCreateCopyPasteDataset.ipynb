{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psgtljEq2sS4","executionInfo":{"status":"ok","timestamp":1671491255264,"user_tz":360,"elapsed":15610,"user":{"displayName":"Ryan Jung","userId":"09833150952226792867"}},"outputId":"faa944b1-6d5f-4ddb-cd17-d7eb02665fe6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Computer_Vision_Final_Project/Computer_Vision_Final_Dataset'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TabyZ90e2vXo","executionInfo":{"status":"ok","timestamp":1671491255500,"user_tz":360,"elapsed":240,"user":{"displayName":"Ryan Jung","userId":"09833150952226792867"}},"outputId":"acd2f874-e9c2-4b56-cbde-d6f1c7f442cc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1qRPzc_kkTeNinCAOMoXj6d_nwu-u_HfH/Computer_Vision_Final_Project/Computer_Vision_Final_Dataset\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"rtZDAOsEqPWP","executionInfo":{"status":"ok","timestamp":1671491263574,"user_tz":360,"elapsed":8076,"user":{"displayName":"Ryan Jung","userId":"09833150952226792867"}}},"outputs":[],"source":["from __future__ import print_function, division\n","import cv2\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","from skimage.color import rgba2rgb\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","\n","from albumentations.pytorch.functional import img_to_tensor\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","plt.ion()   # interactive mode"]},{"cell_type":"markdown","source":["#**Helper Functions**"],"metadata":{"id":"0E0bku_5eW7t"}},{"cell_type":"code","source":["class Rescale(object):\n","    \"\"\"Rescale the image in a sample to a given size.\n","\n","    Args:\n","        output_size (tuple or int): Desired output size. If tuple, output is\n","            matched to output_size. If int, smaller of image edges is matched\n","            to output_size keeping aspect ratio the same.\n","    \"\"\"\n","\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        # image\n","        image = sample['image']\n","\n","        h, w = image.shape[:2]\n","        if isinstance(self.output_size, int):\n","            if h > w:\n","                new_h, new_w = self.output_size * h / w, self.output_size\n","            else:\n","                new_h, new_w = self.output_size, self.output_size * w / h\n","        else:\n","            new_h, new_w = self.output_size\n","\n","        new_h, new_w = int(new_h), int(new_w)\n","\n","        img = transform.resize(image, (new_h, new_w))\n","\n","        # label\n","        label = sample['ground_truth']\n","\n","        h, w = label.shape[:2]\n","        if isinstance(self.output_size, int):\n","            if h > w:\n","                new_h, new_w = self.output_size * h / w, self.output_size\n","            else:\n","                new_h, new_w = self.output_size, self.output_size * w / h\n","        else:\n","            new_h, new_w = self.output_size\n","\n","        new_h, new_w = int(new_h), int(new_w)\n","\n","        label = transform.resize(label, (new_h, new_w))\n","\n","        return {'image': img, 'ground_truth': label}\n","\n","\n","class RandomCrop(object):\n","    \"\"\"Crop randomly the image in a sample.\n","\n","    Args:\n","        output_size (tuple or int): Desired output size. If int, square crop\n","            is made.\n","    \"\"\"\n","\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        if isinstance(output_size, int):\n","            self.output_size = (output_size, output_size)\n","        else:\n","            assert len(output_size) == 2\n","            self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        # image\n","        image  = sample['image']\n","\n","        h, w = image.shape[:2]\n","        new_h, new_w = self.output_size\n","\n","        top = np.random.randint(0, h - new_h)\n","        left = np.random.randint(0, w - new_w)\n","\n","        image = image[top: top + new_h,\n","                      left: left + new_w]\n","\n","        # label\n","        label  = sample['ground_truth']\n","\n","        h, w = label.shape[:2]\n","        new_h, new_w = self.output_size\n","\n","        top = np.random.randint(0, h - new_h)\n","        left = np.random.randint(0, w - new_w)\n","\n","        label = label[top: top + new_h,\n","                      left: left + new_w]\n","\n","        return {'image': image, 'ground_truth': label}\n","\n","class Normalize(object):\n","    \"\"\"Normalize images\"\"\"\n","\n","    def __call_(self, sample):\n","        # image\n","        image = sample['image']\n","        normalize = {\"mean\": [0.485, 0.456, 0.406],\n","                    \"std\": [0.229, 0.224, 0.225]}\n","        image = img_to_tensor(image[0], normalize).unsqueeze(0)\n","\n","        # label\n","        label = sample['ground_truth']\n","        normalize = {\"mean\": [0.485, 0.456, 0.406],\n","                    \"std\": [0.229, 0.224, 0.225]}\n","        label = img_to_tensor(label[0], normalize).unsqueeze(0)\n","\n","        return {'image': image, 'ground_truth': label}\n","\n","class ToTensor(object):\n","    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample):\n","        # image\n","        image = sample['image']\n","\n","        # swap color axis because\n","        # numpy image: H x W x C\n","        # torch image: C x H x W\n","        image = image.transpose((2, 0, 1))\n","\n","        # label\n","        label = sample['ground_truth']\n","\n","        # swap color axis because\n","        # numpy label: H x W x C\n","        # torch label: C x H x W\n","        label = label.transpose((2, 0, 1))\n","\n","        return {'image': torch.from_numpy(image), 'ground_truth': torch.from_numpy(label)}\n","\n","def rgb2gray(rgb):\n","    b, g, r = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]\n","    gray = 0.2989*r + 0.5870*g + 0.1140*b\n","    gray = np.expand_dims(gray, 2)\n","    return gray"],"metadata":{"id":"LwKtdQooeSAT","executionInfo":{"status":"ok","timestamp":1671491263575,"user_tz":360,"elapsed":21,"user":{"displayName":"Ryan Jung","userId":"09833150952226792867"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#**Copy&Paste**\n"],"metadata":{"id":"YidJuM6kffPR"}},{"cell_type":"code","source":["class CopyPasteDataset(Dataset):\n","    \"\"\"Photoshop Detection dataset.\"\"\"\n","\n","    def __init__(self, csv_file, root_dir, transform=None):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with annotations.\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.copypaste_dataset = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.copypaste_dataset)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        # image\n","        img_path = os.path.join(self.root_dir,\n","                                self.copypaste_dataset.iloc[idx, 0])\n","        image = io.imread(img_path)\n","        h, w = image.shape[:2]\n","        image = cv2.resize(image, (512, 512))\n","        if image.shape[2] == 4:\n","          image = rgba2rgb(image)\n","\n","        #  ground truth\n","        label_name = os.path.join(self.root_dir,\n","                                self.copypaste_dataset.iloc[idx, 1])\n","        label = io.imread(label_name)\n","        transforms.CenterCrop((h,w))\n","        label = cv2.resize(label, (512, 512))\n","        if label.shape[2] == 4:\n","          label = rgba2rgb(label)\n","        label = rgb2gray(label)\n","\n","        sample = {'image': image, 'ground_truth': label }\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        # You need to return as tuple so later you can iterate as (for inputs, targets in dataloader)\n","        return sample['image'], sample['ground_truth']"],"metadata":{"id":"jQxdFc9r2nHs","executionInfo":{"status":"ok","timestamp":1671491263575,"user_tz":360,"elapsed":20,"user":{"displayName":"Ryan Jung","userId":"09833150952226792867"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["copypaste_dataset = CopyPasteDataset(csv_file='PhotoshopDetectionDataset.csv', \n","                                     root_dir='',\n","                                     transform=transforms.Compose([\n","                                               Rescale(512),\n","                                               RandomCrop(224),\n","                                               ToTensor(),\n","                                    ]))"],"metadata":{"id":"iX-KkzxCIZot","executionInfo":{"status":"ok","timestamp":1671491263897,"user_tz":360,"elapsed":341,"user":{"displayName":"Ryan Jung","userId":"09833150952226792867"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxA1nLMqKTjj","executionInfo":{"status":"ok","timestamp":1671491263898,"user_tz":360,"elapsed":7,"user":{"displayName":"Ryan Jung","userId":"09833150952226792867"}},"outputId":"9c9e84c3-cd55-45d3-b9e2-6aebd94ffaa9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1qRPzc_kkTeNinCAOMoXj6d_nwu-u_HfH/Computer_Vision_Final_Project\n"]}]}]}